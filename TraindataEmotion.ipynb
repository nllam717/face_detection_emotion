{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TraindataEmotion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IAkksMTbuh99tvUy1i3wLRoMvAx5i7Hp",
      "authorship_tag": "ABX9TyN7u+UPY2/fBTee5iJSdEcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nllam717/face_detection_emotion/blob/master/TraindataEmotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7_6Sg07KlhY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   **Train dữ liệu fer2013 tổng 36000 ảnh, chia thành tập test và train**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNmNxIR2VW0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0a224e2d-c423-48be-8916-de38b58f6d3a"
      },
      "source": [
        "!unzip '/content/drive/My Drive/dataEmotion.csv.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/dataEmotion.csv.zip\n",
            "  inflating: fer2013.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl2Zrms7Kk0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#thư viện dùng trong model\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#thư viện xử lý data, array, matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbgcmFyQKyTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "16d43fcd-d293-4cfa-b569-92a636e6ed46"
      },
      "source": [
        "#nạp data\n",
        "filname = '/content/data.csv'\n",
        "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "names=['emotion','pixels','usage']\n",
        "df=pd.read_csv('/content/data.csv',names=names, na_filter=False)\n",
        "im=df['pixels']\n",
        "df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>emotion</td>\n",
              "      <td>pixels</td>\n",
              "      <td>Usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     usage\n",
              "0  emotion                                             pixels     Usage\n",
              "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
              "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
              "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
              "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
              "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZhXtX0ZK-jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hàm load dataset từ file CSV\n",
        "def getData(filname):\n",
        "    # tổng ảnh = 35887\n",
        "    Y = []\n",
        "    X = []\n",
        "    first = True\n",
        "    for line in open(filname):\n",
        "        if first:\n",
        "            first = False\n",
        "        else:\n",
        "            row = line.split(',')\n",
        "            Y.append(int(row[0]))\n",
        "            X.append([int(p) for p in row[1].split()])\n",
        "\n",
        "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqyfyo7YK_XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d75e2ef-6f84-4b04-eb14-59e05c5470a1"
      },
      "source": [
        "X, Y = getData(filname)\n",
        "num_class = len(set(Y))\n",
        "print(num_class)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVi106xCLH_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras with tensorflow backend\n",
        "N, D = X.shape\n",
        "X = X.reshape(N, 48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY7xzUM1LJiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0) #test_size 0.3 tỉ lệ test 30% data\n",
        "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
        "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2PLvKWHL30H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import *\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVmbUNP6L51P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "89ba8ab6-9129-4d49-9ae4-e00cd17d1b7b"
      },
      "source": [
        "#model tự tạo theo các lớp conv2D để train ảnh theo size 48*48*1\n",
        "def my_model():\n",
        "    model = Sequential()\n",
        "    input_shape = (48,48,1)\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(7))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
        "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        "model=my_model()\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 903       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 2,787,015\n",
            "Trainable params: 2,785,863\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gie5n54nME0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS7v98yoMAd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5be4d16-621f-430c-888d-8ba0642ec017"
      },
      "source": [
        "path_model='model_filter2.h5' # save model at this location after each epoch\n",
        "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
        "model=my_model() # create the model\n",
        "K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
        "# fit the model\n",
        "h=model.fit(x=X_train,     \n",
        "            y=y_train, \n",
        "            batch_size=64, \n",
        "            epochs=50, \n",
        "            verbose=1, \n",
        "            validation_data=(X_test,y_test),\n",
        "            shuffle=True,\n",
        "            callbacks=[\n",
        "                ModelCheckpoint(filepath=path_model),\n",
        "            ]\n",
        "            )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25120 samples, validate on 10767 samples\n",
            "Epoch 1/50\n",
            "25120/25120 [==============================] - 22s 874us/step - loss: 1.7139 - accuracy: 0.3306 - val_loss: 1.5903 - val_accuracy: 0.3737\n",
            "Epoch 2/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 1.3918 - accuracy: 0.4688 - val_loss: 1.4625 - val_accuracy: 0.4552\n",
            "Epoch 3/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 1.1995 - accuracy: 0.5484 - val_loss: 1.4364 - val_accuracy: 0.4626\n",
            "Epoch 4/50\n",
            "25120/25120 [==============================] - 15s 592us/step - loss: 1.0648 - accuracy: 0.5996 - val_loss: 1.1723 - val_accuracy: 0.5617\n",
            "Epoch 5/50\n",
            "25120/25120 [==============================] - 15s 591us/step - loss: 0.9359 - accuracy: 0.6516 - val_loss: 1.1717 - val_accuracy: 0.5610\n",
            "Epoch 6/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 0.7794 - accuracy: 0.7129 - val_loss: 1.2194 - val_accuracy: 0.5756\n",
            "Epoch 7/50\n",
            "25120/25120 [==============================] - 15s 591us/step - loss: 0.6148 - accuracy: 0.7816 - val_loss: 1.3051 - val_accuracy: 0.5599\n",
            "Epoch 8/50\n",
            "25120/25120 [==============================] - 15s 591us/step - loss: 0.4289 - accuracy: 0.8494 - val_loss: 1.4156 - val_accuracy: 0.5839\n",
            "Epoch 9/50\n",
            "25120/25120 [==============================] - 15s 587us/step - loss: 0.2947 - accuracy: 0.9023 - val_loss: 1.5745 - val_accuracy: 0.5833\n",
            "Epoch 10/50\n",
            "25120/25120 [==============================] - 15s 593us/step - loss: 0.2009 - accuracy: 0.9362 - val_loss: 1.6812 - val_accuracy: 0.5748\n",
            "Epoch 11/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 0.1500 - accuracy: 0.9529 - val_loss: 1.9131 - val_accuracy: 0.5643\n",
            "Epoch 12/50\n",
            "25120/25120 [==============================] - 15s 584us/step - loss: 0.1317 - accuracy: 0.9588 - val_loss: 1.7808 - val_accuracy: 0.5797\n",
            "Epoch 13/50\n",
            "25120/25120 [==============================] - 15s 587us/step - loss: 0.1185 - accuracy: 0.9625 - val_loss: 2.0217 - val_accuracy: 0.5579\n",
            "Epoch 14/50\n",
            "25120/25120 [==============================] - 15s 581us/step - loss: 0.0931 - accuracy: 0.9719 - val_loss: 2.4140 - val_accuracy: 0.5487\n",
            "Epoch 15/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0976 - accuracy: 0.9684 - val_loss: 2.3112 - val_accuracy: 0.5822\n",
            "Epoch 16/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0924 - accuracy: 0.9693 - val_loss: 2.2080 - val_accuracy: 0.5775\n",
            "Epoch 17/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0832 - accuracy: 0.9719 - val_loss: 2.1619 - val_accuracy: 0.5801\n",
            "Epoch 18/50\n",
            "25120/25120 [==============================] - 15s 582us/step - loss: 0.0714 - accuracy: 0.9771 - val_loss: 2.3643 - val_accuracy: 0.5473\n",
            "Epoch 19/50\n",
            "25120/25120 [==============================] - 15s 582us/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 2.5284 - val_accuracy: 0.5793\n",
            "Epoch 20/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 2.4211 - val_accuracy: 0.5676\n",
            "Epoch 21/50\n",
            "25120/25120 [==============================] - 15s 585us/step - loss: 0.0794 - accuracy: 0.9742 - val_loss: 2.2874 - val_accuracy: 0.5793\n",
            "Epoch 22/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 2.3556 - val_accuracy: 0.5831\n",
            "Epoch 23/50\n",
            "25120/25120 [==============================] - 15s 580us/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 2.4045 - val_accuracy: 0.5845\n",
            "Epoch 24/50\n",
            "25120/25120 [==============================] - 15s 582us/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 2.4152 - val_accuracy: 0.5851\n",
            "Epoch 25/50\n",
            "25120/25120 [==============================] - 15s 585us/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 2.6831 - val_accuracy: 0.5851\n",
            "Epoch 26/50\n",
            "25120/25120 [==============================] - 15s 584us/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 2.5476 - val_accuracy: 0.5813\n",
            "Epoch 27/50\n",
            "25120/25120 [==============================] - 15s 585us/step - loss: 0.0578 - accuracy: 0.9797 - val_loss: 2.4702 - val_accuracy: 0.5835\n",
            "Epoch 28/50\n",
            "25120/25120 [==============================] - 15s 591us/step - loss: 0.0623 - accuracy: 0.9784 - val_loss: 2.5367 - val_accuracy: 0.5935\n",
            "Epoch 29/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 2.5131 - val_accuracy: 0.5847\n",
            "Epoch 30/50\n",
            "25120/25120 [==============================] - 15s 588us/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 2.6433 - val_accuracy: 0.5795\n",
            "Epoch 31/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0452 - accuracy: 0.9852 - val_loss: 2.7811 - val_accuracy: 0.5788\n",
            "Epoch 32/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 2.7540 - val_accuracy: 0.5769\n",
            "Epoch 33/50\n",
            "25120/25120 [==============================] - 15s 586us/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 2.8141 - val_accuracy: 0.5587\n",
            "Epoch 34/50\n",
            "25120/25120 [==============================] - 15s 589us/step - loss: 0.0426 - accuracy: 0.9862 - val_loss: 2.7969 - val_accuracy: 0.5895\n",
            "Epoch 35/50\n",
            "25120/25120 [==============================] - 15s 581us/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 2.9337 - val_accuracy: 0.5883\n",
            "Epoch 36/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 2.8047 - val_accuracy: 0.5855\n",
            "Epoch 37/50\n",
            "25120/25120 [==============================] - 15s 592us/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 2.7827 - val_accuracy: 0.5829\n",
            "Epoch 38/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 0.0479 - accuracy: 0.9833 - val_loss: 2.9116 - val_accuracy: 0.5744\n",
            "Epoch 39/50\n",
            "25120/25120 [==============================] - 15s 583us/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 2.8490 - val_accuracy: 0.5844\n",
            "Epoch 40/50\n",
            "25120/25120 [==============================] - 15s 582us/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 2.9380 - val_accuracy: 0.5911\n",
            "Epoch 41/50\n",
            "25120/25120 [==============================] - 15s 584us/step - loss: 0.0389 - accuracy: 0.9864 - val_loss: 2.7565 - val_accuracy: 0.5810\n",
            "Epoch 42/50\n",
            "25120/25120 [==============================] - 15s 589us/step - loss: 0.0486 - accuracy: 0.9839 - val_loss: 2.9577 - val_accuracy: 0.5790\n",
            "Epoch 43/50\n",
            "25120/25120 [==============================] - 15s 593us/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 2.7169 - val_accuracy: 0.5938\n",
            "Epoch 44/50\n",
            "25120/25120 [==============================] - 15s 591us/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 2.9435 - val_accuracy: 0.5889\n",
            "Epoch 45/50\n",
            "25120/25120 [==============================] - 15s 592us/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 3.0017 - val_accuracy: 0.5905\n",
            "Epoch 46/50\n",
            "25120/25120 [==============================] - 15s 592us/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 2.9857 - val_accuracy: 0.5752\n",
            "Epoch 47/50\n",
            "25120/25120 [==============================] - 15s 590us/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 2.9867 - val_accuracy: 0.5830\n",
            "Epoch 48/50\n",
            "25120/25120 [==============================] - 15s 588us/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 3.1751 - val_accuracy: 0.5745\n",
            "Epoch 49/50\n",
            "25120/25120 [==============================] - 15s 593us/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 2.9396 - val_accuracy: 0.5937\n",
            "Epoch 50/50\n",
            "25120/25120 [==============================] - 15s 593us/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 3.0097 - val_accuracy: 0.5880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s852A0E0MGKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# generate dataset\n",
        "\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2cOWlmtQGBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#overfitting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score, learning_curve, validation_curve\n",
        "\n",
        "import matplotlib as mpl\n",
        "# Default parameters for matplotlib plots\n",
        "mpl.rcParams['xtick.labelsize'] = 22\n",
        "mpl.rcParams['ytick.labelsize'] = 22\n",
        "mpl.rcParams['figure.figsize'] = (10, 8)\n",
        "mpl.rcParams['axes.facecolor'] = (0.9,0.9,0.9)\n",
        "mpl.rcParams['lines.linewidth'] = 2\n",
        "mpl.rcParams['axes.grid'] = True\n",
        "mpl.rcParams['grid.color'] = 'w'\n",
        "mpl.rcParams['xtick.top'] = True\n",
        "mpl.rcParams['ytick.right'] = True\n",
        "mpl.rcParams['grid.linestyle'] = '--'\n",
        "mpl.rcParams['legend.fontsize'] = 22\n",
        "mpl.rcParams['legend.facecolor'] = [1,1,1]\n",
        "mpl.rcParams['legend.framealpha'] = 0.75\n",
        "mpl.rcParams['axes.labelsize'] = 22"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj8h35TlZYNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_1 = RandomForestClassifier(n_estimators=100, bootstrap=True, random_state=0)\n",
        "clf_1.fit(X_train, y_train)\n",
        "# Number of folds for cross validation\n",
        "num_folds = 7\n",
        "\n",
        "\n",
        "### đang lỗi"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}